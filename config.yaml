experiment_name      : "AES-EXP-17"
training_filename    : "final_train.csv"
data_dir             : "./input/"
artifacts_dir        : "./output/"
output_dir           : "${artifacts_dir}/${experiment_name}"
fold                 : 0
model_id             : "microsoft/deberta-v3-base"
num_labels           : 6
wandb_log            : True
wandb_project_name   : "AES"
notes                : "Added mean pooling"
truncation           : True
max_length           : 1024
seed                 : 2024
full_fit             : False
notify_discord       : True
num_freez_layers     : 4

training_args :
  learning_rate               : 4.0e-5
  per_device_train_batch_size : 4
  per_device_eval_batch_size  : 8
  num_train_epochs            : 1
  weight_decay                : 0.01
  evaluation_strategy         : 'epoch'
  save_strategy               : 'no'
  push_to_hub                 : False
  warmup_ratio                : 0.1
  fp16                        : True
  lr_scheduler_type           : 'cosine'
  # gradient_accumulation_steps : 2,
  # gradient_checkpointing      : True